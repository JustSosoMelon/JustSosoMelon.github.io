并发编程中两个关键问题：
线程之间的通信与线程之间的同步机制。
线程通信有两种方式：
  1. 采用共享内存，线程之间通过读写共享内存中的工程状态来隐式通信
  2. 采用消息传递的方式进行显示的通信，线程之间没有公共状态。
同步是指程序用于控制不同线程之间操作发生的相对顺序的机制。
  1. 在共享内存并发模型里，同步通过程序猿显示指定某个方法或某段代码需要再线程之间互斥执行。
  2. 在消息传递并发模型中，由于消息的发送一定是在接收之前，因此线程之间已经隐式同步。

Java采用共享内存模型，通信过程是隐式的，对程序透明。

Java中所有实例域、静态域和数组元素都存储在堆内存中，在线程之间共享。共享变量即指这些，存在内存可见性问题。
Local变量，Method参数以及ExceptionHandle参数都不会共享，不存在内存可见性问题。

JMM（Java Memory Model）定义了线程和主内存之间的抽象关系。共享变量存储在主内存才可以被共享，但每个线程存储了自己的共享变量副本在本地内存（本地内存是抽象概念，包括缓存，写缓存，寄存在等其他硬件和编译器优化带来的共享内存刷新延时都是本地内存）。
eg：写缓冲区对自己的处理器可见，但对其他处理器不可见，由于写缓存的批量刷新到共享内存，会导致处理器执行的内存操作顺序可能与内存实际的操作执行顺序不一致（内存指共享内存）。现代处理器会允许对写-读（store-load）操作重排序。
为了保证内存的可见性，java编译器在生成指令序列时在适当位置插入内存屏障指令来禁止特定类型的处理器冲排序。
如eg中的情况可以增加storeLoda barriers来禁止写-读操作重排序。但这个内存屏障指令开销很高。

如果一个操作执行的结果需要对另一个操作可见，两个操作之间必须存在happens-before关系，是操作可见性上的顺序，并不是操作执行的顺序。这个规则能禁止一个或多个编译器和处理器重排序规则。即如果两个操作不相互依赖内存的可见性，则允许冲排序。
重要的happens-before规则如下：（happens-before即会刷新的共享变量）
  1.  一个线程中的操作，由于本地内存可见，happens-before适用
  2. 监视器锁规则：对于一个监视器的解锁，happens-before于随后对这个监视器的加锁。（加锁后刷新监视器共享变量）
锁除了让临界区互斥执行外，还可以让释放锁的线程向获取同一个锁的线程发送消息。
volatile仅仅保证单个volatile变量的读写具有原子性，而锁的互斥执行特性可以确保整个临界区代码的执行具有原子性。其实volatile和写和读构成的是类似于半开的锁，而锁其实是利用了volatile的读写和CAS（compareAndSet，原子操作的方式更新volatile变量，先读后写）实现闭合的锁。
  3. volatile变量规则：对于volatile域的写，happens-before与任意后续对这个域的读。
上面讲的是volatile变量自身的特性，而其对线程内存可见性的影响比volatile自身特性更重要。
  4. jdk5以后volatile域的读写可以实现线程间的通信。即volatile的写与锁的释放有相同的内存语义，读与锁的获取具有相同的内存语义。
*当写一个volatile变量时，JMM会把线程对应的本地内存中的共享变量值刷新到主内存
*当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将必须从主内存读取共享变量。
当线程A写一个volatile变量后，B线程读一个volatile变量，A线程在写volatile变量之前所有可见的共享变量（即程序语义或顺序上可见的共享变量），在B读取同一个volatile变量后，立即变得对B线程可见。
  5. 传递性：如果A hb B，B hb C，那么A hb C

在单个处理器中执行的之林序列和单个线程中执行的操作，编译器和处理器在对操作做冲排序时，会遵守数据依赖性，不会改变存在数据依赖关系的两个操作的执行顺序。即as-if-serial语义，即不管编译器或处理器怎么重排序，单线程的程序执行结果不能被改变，因此有数据依赖关系的操作是不会被重排序的。因此单线程程序无需关心重排序和内存可见性问题。

当程序未正确同步时，就可能会存在数据竞争。java内存模型规范对数据竞争的定义如下：
．在一个线程中写一个变量，
．在另一个线程读同一个变量，
．而且写和读没有通过同步来排序。
JMM对正确同步的多线程程序的内存一致性做了如下保证：
如果程序是正确同步的，程序的执行将具有顺序一致性（sequentially
consistent）一即程序的执行结果与该程序在顺序一致性内存模型中的执行结
果相同。马上我们将会看到，这对于程序员来说是一个极强的保证。这里的同
步是指广义上的同步，包括对常用同步原语（synchronized,volatile和final)
的正确使用。

未同步程序在JMM中的执行时，整体上是无序的，其执行结果无法预知。未同步

程序在两个模型中的执行特性有下面几个差异：

1．顺序一致性模型保证单线程内的操作会按程序的顺序执行，而JMM不保证单
线程内的操作会按程序的顺序执行（比如上面正确同步的多线程程序在临界区
内的重排序）。这一点前面已经讲过了，这里就不再鳌述。
2．顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而JMM不保证
所有线程能看到一致的操作执行顺序。这一点前面也已经讲过，这里就不再赞
述。
3.JMM不保证对64位的Iong型和double型变量的读／写操作具有原子性，而
顺序一致性模型保证对所有的内存读／写操作都具有原子性。（其实在JSR-133 jdk5之后，所有的读操作都具有原子性了，必须在单个总线任务中完成）
AQS：抽象队列同步（非阻塞数据结构和原子变量类）
AbstractQueuedSynchronizer，concurrent包里的及处理都是用该模式实现的。

final：
对final域的读写更像是普通的变量方位，编译器和处理器遵守两个重排规则：
1. 构造函数内对fina写入，与随后把这个被构造对象的引用复制给一个引用变量，不能重排
2. 初次读一个包含final域的对象的引用，与随后初次读这个final域，不能重排。


JSR一133为什么要增强final的语义

在旧的Java内存模型中，最严重的一个缺陷就是线程可能看到final域的值会改
变。比如，一个线程当前看到一个整形final域的值为O（还未初始化之前的默认
值），过一段时间之后这个线程再去读这个fina｝域的值时，却发现值变为了1
（被某个线程初始化之后的值）。最常见的例子就是在旧的Java内存模型中，
String的值可能会改变（参考文献37中有一个具体的例子，感兴趣的读者可以自
行参考，这里就不赞述了）。
内了修补这个漏洞，JSR一133专家组增强了fin。！的语义。通过为finol域增加写和
读重排序规则，可以为」。va程序员提供初始化安全保证：只要对象是正确构造的
（被构造对象的引用在构造函数中没有“逸出“)，那么不需要使用同步（指l。。k
和volatile的使用），就可以保证任意线程都能看到这个fina！域在构造函数中被
初始化之后的值。


总结：
顺序一致性内存模型是理论参考模型，JMM核处理器内存模型的设计会对其进行放松，使得处理器和编译器可以有优化空间，增加执行性能。
由于处理器有写缓存区，几乎所有处理器内存模型都允许写读重排序。导致房钱处理器可以比其他处理器先看到临时保存在写缓存区中的变量。
内存模型越弱，对处理器的束缚越少，执行性能越强。常见的处理器内存模型都比JMM弱。java编译器生成字节码时，会在执行序列的适当位置插入内存屏障限制处理器的冲排序。各个处理器的内存模型也不相同，JMM在不同的处理器中需要插入的内存屏障数量和种类也不同。但对于程序猿，呈现了一致的内存模型，即JMM。

JMM的设计，平衡下面两种矛盾
  1. 程序猿希望基于强内存模型编写代码
  2. 编译器和处理器希望语言级别的内存模型对他们束缚越少越好，希望弱内存模型。
单处理器单线程程序或正确同步的多线程程序中，JMM禁止会改变程序执行结果的重排序，其余让编译器和处理器尽力去优化。比如一个锁只被单个线程访问，编译器会消除这个锁，类似的volatile的读写都在一个线程中，也会被优化为普通变量。

JMM的内存可见性保证：
单线程程序不存在内存可见性问题；
正确同步的多线程程序即执行具有顺序一致性的多线程程序（用同步方式保证了执行结果与顺序一致性内存模型中的执行结果相同）。
未同步或正确同步的多线程程序，JMM为它们提供了最小安全性保证，即执行时读取的值，要么是之前某个线程写入的值，要么是默认值（0，null，false），因为初始化堆内存时一定先清零。

JSR-133对旧内存模型的修补：
1. 增强volatile的内存语义，旧内存模型允许volatile变量与普通变量重排序。JSR-133严格限制volatile变量与普通变量的重排序，前后均插入了内存屏障指令，使得volatile的写读和锁的释放与获取具有相同的内存语义。
2. 增强final的内存语义，在旧内存模型中，多次读取一个final变量的值可能会不相同，增强后，禁止了final引用读取和final引用对应的域读取的重排，以及禁止了构造函数中初始化final域并赋值给final引用的泄漏（防止构造函数没结束就被其他线程访问）。使得final具有了初始化安全性，即只可能被初始化一次，一旦开始初始化，只能读到初始化后的值，并且以后都不变。


